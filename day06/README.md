# Week 08: Tutorial 7

This is the tutorial about MDPs and stochastic planning.

## Goals

- Understand the Bellman equation
- Implement Value Iteration
- Implement Policy Iteration
- Analyse the various parameters of an MDP in the results

## TODO Rest of instructions